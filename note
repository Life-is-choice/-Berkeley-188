
显然，人类距离真正的人工智能尚远，虽然没有统一的定义和理论，但仍有许多有价值的形式、方法值得学习。我们使用合适的理论来指导我们去实现特定领域的Agent

定义世界环境状态state：世界的特征被提取成向量，将向量空间划分成一个原子化的状态空间集合
定义Agent：对状态采取行动，以期望达成目标状态
定义行为act：一个act完成后，其结果是state集合中的一个元素，act往往拥有函数的形式
定义规划：当环境是确定的，S-act->S',搜索空间路径以规划出完整的act(A*,HTN)
定义策略：当环境是不确定的,只有P(S'|S,a),预测效用采取一个act(MDP，reinforce)

Agent逻辑有以下伪代码
whlie(1){
if(act_queue.empty()){
  handle = map2act(check_state())
  if(handle){do(handle)}
  else{
    if(cost_time>tolerance){do(DEFAULT)}
    else do(plan)/do(strategy)
    }
  }
}

<规划>
1演绎类方法
搜素 = 连续演绎。可以注意方法的可评价性、有序性
博弈 = 逆向演绎。演绎时发现没戏就放弃称为减枝


2雕刻类方法






















1Planning是很简单的线性迭代

-1演绎法
从初始状态开始遍历。其中有两个技巧
1搜子集来控制内存
2在每一层预设失败、提前使用一个评价函数评价下一层来做优化

博弈是逆向演绎，发现没戏就放弃称为减枝

-2离散迭代

如果状态有启发信息，可以直接当成最值问题来迭代求解。
不同于数值分析中的下山法，我们可以通过检测状态是否符号要求来判断是局部收敛还是正解来决定是否重启，所以这个方法是完备的

特别地，将此方法并行然后取表现最好的称为局部束搜索。在局部束搜索中，不取表现最好的而是将并行实例进行合并杂糅称为遗传算法

模拟退火随机选一个后继看评价。
IF(变好)采纳
ELSE IF(变差)以随时间变小的概率采纳
ELSE 重选后继
